# 1、说明 #

wrk 的一个很好的特性就是能用很少的线程压出很大的并发量， 原因是它使用了一些操作系统特定的高性能 I/O 机制, 比如 select, epoll, kqueue 等。 其实它是复用了 redis 的 ae 异步事件驱动框架. 确切的说 ae 事件驱动框架并不是 redis 发明的, 它来自于 Tcl的解释器 jim, 这个小巧高效的框架, 因为被 redis 采用而更多的被大家所熟知.

wrk 只能运行在 Unix 类的系统上. 比如 linux, mac, solaris 等. 也只能在这些系统上编译.  

# 2、安装 #

选择linux服务器：10.213.140.21。安装目录：/app
如果没安装git，则安装：

    [root@vane-turn01 home]# yum -y install git
    [root@vane-turn01 home]# git clone https://github.com/wg/wrk.git
    [root@vane-turn01 home]# cd wrk
    [root@vane-turn01 home]# make

安装好后新增加wrk文件

    [root@vane-turn01 wrk]# pwd
    /home/wrk
    [root@vane-turn01 wrk]# ll
    total 3036
    -rw-r--r--. 1 root root 910 Dec 20 08:27 CHANGES
    drwxr-xr-x. 2 root root4096 Dec 20 08:27 deps
    -rw-r--r--. 1 root root 916 Dec 20 08:27 INSTALL
    -rw-r--r--. 1 root root   10489 Dec 20 08:27 LICENSE
    -rw-r--r--. 1 root root2599 Dec 20 08:27 Makefile
    -rw-r--r--. 1 root root5420 Dec 20 08:27 NOTICE
    drwxr-xr-x. 9 root root4096 Dec 20 08:37 obj
    -rw-r--r--. 1 root root2856 Dec 20 08:27 README
    -rw-r--r--. 1 root root4158 Dec 20 08:27 SCRIPTING
    drwxr-xr-x. 2 root root4096 Dec 20 08:27 scripts
    drwxr-xr-x. 2 root root4096 Dec 20 08:27 src
    -rwxr-xr-x. 1 root root 3043822 Dec 20 08:37 wrk
    
# 3、运行 #
执行测试命令：

    ./wrk  -t2 -c10 -d5s http://www.baidu.com

意思是对 baidu.com 进行测试，启动 2个线程，10个并发，持续运行5秒。
建议线程数不要过多，可以设置为核数的2到4倍。多了反而因为线程切换过多造成效率降低. 因为 wrk 不是使用每个连接一个线程的模型, 而是通过异步网络 io 提升并发量. 所以网络通信不会阻塞线程执行. 这也是 wrk 可以用很少的线程模拟大量网路连接的原因. 而现在很多性能工具并没有采用这种方式, 而是采用提高线程数来实现高并发. 所以并发量一旦设的很高, 测试机自身压力就很大. 测试效果反而下降. 

    Running 5s test @ http://www.baidu.com
      2 threads and 10 connections
      Thread Stats   Avg  	Stdev 	Max   +/- Stdev
    	Latency   7.73ms	7.70ms 208.87ms   99.14%
    	Req/Sec   680.13 	44.68   787.00 	  69.00%
      6787 requests in 5.01s, 99.44MB read
      Socket errors: connect 0, read 36, write 0, timeout 0
    Requests/sec:   1353.42
    Transfer/sec:   19.83MB

Latency: 可以理解为响应时间, 有平均值, 标准偏差, 最大值, 正负一个标准差占比. 
Req/Sec: 每个线程每秒钟的完成的请求数, 同样有平均值, 标准偏差, 最大值, 正负一个标准差占比.
一般我们来说我们主要关注平均值和最大值. 标准差如果太大说明样本本身离散程度比较高. 有可能系统性能波动很大.

wrk 默认超时时间是1秒. 这个有点短. 可以设置为10秒. 这个看上去合理一点. 
如果这样执行命令:  

    ./wrk  -t2 -c10 -d30s -T30s http://www.baidu.com

可以看到超时数就大大降低了, Socket errors 那行没有了.想看看响应时间的分布情况可以加上--latency参数: 
    ./wrk -t2 -c10 -d30s -T30s --latency http://www.baidu.com

    [root@vane-turn01 wrk]# ./wrk -t2 -c10 -d30s -T30s --latency http://www.baidu.com
    Running 30s test @ http://www.baidu.com
      2 threads and 10 connections
      Thread Stats   Avg  	Stdev 		Max   	+/- Stdev
    	Latency 	7.61ms  10.69ms 	430.49ms   99.64%
    	Req/Sec   	631.48	159.94   	820.00 	   87.15%
      Latency Distribution
	     50%	6.86ms
	     75%	7.66ms
	     90%	8.74ms
	     99%   12.94ms
      22602 requests in 30.07s, 331.15MB read
      Socket errors: connect 0, read 6295, write 0, timeout 0
    Requests/sec:751.56
    Transfer/sec: 11.01MB

# 四、lua 脚本 #
wrk 支持 lua 脚本. 在这个脚本里你可以修改 method, header, body, 可以对 response 做一下自定义的分析. 因为是 lua 脚本, 其实这给了你无限的可能. 但是这样一个强大的功能如果不谨慎使用, 会降低测试端的性能, 测试结果也受到影响. 

一般修改method, header, body不会影响测试端性能, 但是操作 request, response 就要格外谨慎了. 

我们通过一些测试场景再看看怎么使用 lua 脚本. POST + header + body. 

首先在当前目录创建一个 authpost.lua 的文件: 

    wrk.method = "POST"
	wrk.body = '{"devSn":"add","devKey":"abc"}' 
	wrk.headers["Content-Type"] = "application/json"

	-- wrk.body   = "foo=bar&baz=quux"
	-- wrk.headers["Content-Type"] = "plan/text"

就这三行就可以了, 当然 headers 可以加入任意多的内容. 然后执行: 

    ./wrk -t2 -c10 -d30s -T30s --script=post.lua --latency http://www.baidu.com

五、
nohup java -Xms4096m -Xmx4096m -Djava.rmi.server.hostname=192.168.18.102 -Dcom.sun.management.jmxremote.port=1090 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -DLog4jContextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -jar auth.jar 100000000000 >/dev/null &
curl -H "Content-type: text/plain" -G -d "devKey=abc" http://192.168.1.109:8080/auth/gw/active?devSn=add
curl -H "Content-type: application/json" -X POST -d "{\"devSn\":\"add\",\"devKey\":\"abc\"}" http://192.168.1.109:8080/auth/gw/active
./wrk -t8 -c32 -d30s -T10s --script=authpost.lua --latency http://10.213.142.63:8080/auth/gw/active


测试结果
服务端 AMD Opteron(tm) Processor 4171 HE 8核 14G 服务只用了4G
客户端 AMD Opteron(tm) Processor 4171 HE 8核 14G
dropwizard框架写的restapi接口，启动命令：
看上去dropwizard性能较差。
nohup java -Xms4096m -Xmx4096m -jar auth.jar server auth.yml >/dev/null &

[root@vanelife-App3 wrk]# ./wrk -t1 -c1 -d30s -T10s --script=authpost.lua --latency http://10.213.142.63:8080/auth/gw/active

	Running 30s test @ http://10.213.142.63:8080/auth/gw/active
	  1 threads and 1 connections
	  Thread Stats   Avg      Stdev     Max   +/- Stdev
	    Latency     3.51ms    3.14ms  60.56ms   78.46%
	    Req/Sec   318.42     48.54   424.00     76.51%
	  Latency Distribution
	     50%    1.99ms
	     75%    5.18ms
	     90%    7.24ms
	     99%   11.42ms
	  9540 requests in 30.10s, 1.83MB read
	Requests/sec:    316.94
	Transfer/sec:     62.21KB
    
[root@vanelife-App3 wrk]# ./wrk -t8 -c10 -d30s -T10s --script=authpost.lua --latency http://10.213.142.63:8080/auth/gw/active

	Running 30s test @ http://10.213.142.63:8080/auth/gw/active
	  8 threads and 10 connections
	  Thread Stats   Avg      Stdev     Max   +/- Stdev
	    Latency     8.79ms    7.99ms  89.27ms   81.24%
	    Req/Sec   125.78     36.10   282.00     69.83%
	  Latency Distribution
	     50%    7.65ms
	     75%   11.47ms
	     90%   18.73ms
	     99%   37.31ms
	  30116 requests in 30.09s, 5.77MB read
	Requests/sec:   1000.97
	Transfer/sec:    196.48KB

[root@vanelife-App3 wrk]# ./wrk -t8 -c32 -d30s -T10s --script=authpost.lua --latency http://10.213.142.63:8080/auth/gw/active

	Running 30s test @ http://10.213.142.63:8080/auth/gw/active
	  8 threads and 32 connections
	  Thread Stats   Avg      Stdev     Max   +/- Stdev
	    Latency    29.30ms   28.11ms 238.56ms   76.73%
	    Req/Sec   166.66     45.66   330.00     67.83%
	  Latency Distribution
	     50%   22.27ms
	     75%   42.34ms
	     90%   67.05ms
	     99%  125.39ms
	  39937 requests in 30.10s, 7.66MB read
	Requests/sec:   1326.80
	Transfer/sec:    260.44KB


dropwizard测试结果
	java -jar dropwizard-1.0-SNAPSHOT.jar server hello.yml
	nohup java -Xms4096m -Xmx4096m -jar dropwizard-1.0-SNAPSHOT.jar server hello.yml >/dev/null &
	curl -X GET http://192.168.0.9:8080/rest/hello
	./wrk -t1 -c1 -d30s -T10s --latency http://192.168.0.9:8080/rest/hello

[root@vanelife-mysql wrk]# ./wrk -t8 -c32 -d30s -T10s --latency http://192.168.0.9:8080/rest/hello

	Running 30s test @ http://192.168.0.9:8080/rest/hello
	  8 threads and 32 connections
	  Thread Stats   Avg      Stdev     Max   +/- Stdev
	    Latency     1.85ms    1.66ms  34.84ms   90.97%
	    Req/Sec     2.48k   340.53     3.29k    66.88%
	  Latency Distribution
	     50%    1.34ms
	     75%    2.04ms
	     90%    3.33ms
	     99%    8.57ms
	  592771 requests in 30.02s, 63.88MB read
	Requests/sec:  19746.03
	Transfer/sec:      2.13MB

java -jar resteasy-netty4-1.0-SNAPSHOT.jar
nohup java -Xms4096m -Xmx4096m -jar resteasy-netty4-1.0-SNAPSHOT.jar >/dev/null &

[root@vanelife-mysql wrk]# ./wrk -t8 -c32 -d30s -T10s --latency http://192.168.0.9:8080/rest/hello

    Running 30s test @ http://192.168.0.9:8080/rest/hello
      8 threads and 32 connections
      Thread Stats   Avg  Stdev Max   +/- Stdev
    	Latency 2.00ms1.14ms  34.56ms   88.93%
    	Req/Sec 2.08k   198.05 4.24k70.05%
      Latency Distribution
     	50%1.77ms
     	75%2.18ms
     	90%3.03ms
     	99%6.27ms
      497035 requests in 30.10s, 55.93MB read
    Requests/sec:  16513.90
    Transfer/sec:  1.86MB

java -jar nativenetty-1.0-SNAPSHOT.jar
nohup java -Xms4096m -Xmx4096m -Djava.rmi.server.hostname=192.168.0.9 -Dcom.sun.management.jmxremote.port=1090 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar nativenetty-1.0-SNAPSHOT.jar >/dev/null &

[root@vanelife-mysql wrk]# ./wrk -t8 -c32 -d30s -T10s --latency http://192.168.0.9:8080/rest/hello

    Running 30s test @ http://192.168.0.9:8080/rest/hello
      8 threads and 32 connections
      Thread Stats   Avg  Stdev Max   +/- Stdev
    	Latency 1.21ms0.96ms  24.34ms   92.65%
    	Req/Sec 3.60k   356.97 4.51k66.71%
      Latency Distribution
     	50%0.98ms
     	75%1.25ms
     	90%1.86ms
     	99%5.49ms
      859980 requests in 30.02s, 82.01MB read
    Requests/sec:  28642.23
    Transfer/sec:  2.73MB

[root@vanelife-mysql wrk]# ./wrk -t8 -c64 -d30s -T10s --latency http://192.168.0.9:8080/rest/hello

	Running 30s test @ http://192.168.0.9:8080/rest/hello
	  8 threads and 64 connections
	  Thread Stats   Avg      Stdev     Max   +/- Stdev
	    Latency     1.87ms    1.72ms  59.04ms   95.74%
	    Req/Sec     4.53k   449.89    11.23k    76.68%
	  Latency Distribution
	     50%    1.66ms
	     75%    1.98ms
	     90%    2.62ms
	     99%    6.10ms
	  1082684 requests in 30.10s, 103.25MB read
	Requests/sec:  35972.72
	Transfer/sec:      3.43MB



跨网络，打印每请求的日志
[root@vanelife-mysql wrk]# ./wrk -t8 -c64 -d30s -T10s --latency http://192.168.0.9:8080/rest/hello

    Running 30s test @ http://192.168.0.9:8080/rest/hello
      8 threads and 64 connections
      Thread Stats   Avg  Stdev Max   +/- Stdev
    	Latency 4.02ms3.22ms  52.55ms   78.54%
    	Req/Sec 2.21k   378.13 3.14k63.25%
      Latency Distribution
     	50%3.33ms
     	75%5.36ms
     	90%7.96ms
     	99%   15.40ms
      528270 requests in 30.01s, 50.38MB read
    Requests/sec:  17601.22
    Transfer/sec:  1.68MB

服务器和客户端在同一台机器，不跨网络打印没请求日志
[root@vane-turn01 wrk]# ./wrk -t8 -c32 -d30s -T10s --latency http://192.168.0.9:8080/rest/hello

    Running 30s test @ http://192.168.0.9:8080/rest/hello
      8 threads and 32 connections
      Thread Stats   Avg  Stdev Max   +/- Stdev
    	Latency 2.28ms2.25ms  30.08ms   86.92%
    	Req/Sec 2.15k   243.18 2.82k67.75%
      Latency Distribution
    	50%1.85ms
     	75%3.20ms
     	90%5.10ms
     	99%   10.57ms
      513600 requests in 30.08s, 48.98MB read
    Requests/sec:  17075.52
    Transfer/sec:  1.63MB

